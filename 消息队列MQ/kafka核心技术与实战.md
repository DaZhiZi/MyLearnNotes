# 《kafka 核心技术与实战》笔记

## 01 消息引擎系统

Apache Kafka 是一款开源的消息引擎系统。

消息引擎两种模型：

- 点对点模型：也叫消息队列模型。如果拿上面那个“民间版”的定义来说，那么系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。日常生活的例子比如电话客服就属于这种模型：同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。
- 发布 / 订阅模型：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布 / 订阅模型。

为什么要使用它？

**削峰填谷**。所谓的**削峰填谷**就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。

## 02 一篇文章带你快速搞定 Kafka 术语

- 生产者：向主题发布消息的客户端应用程序称为生产者（Producer）, 生产者程序通常持续不断地向一个或多个主题发送消息，而订阅这些主题消息的客户端应用程序就被称为消费者
- 消费者：订阅这些主题的程序应用就称为**消费者** (Consumer)，与生产者类似，消费者也可以同时订阅多个主题的消息。
- 客户端（Clients）：把生产者和消费者统称为客户端
- 服务器端：kafka 服务器端由被称为 Broker 的服务进程构成，即一个 kafka 集群由多个 Broker 构成，Broker 来接受和处理客户端发来的请求，以及对消息的持久化。常见的做法是把 Broker 分散在不同的机器上，保证高可用
- 备份机制（Replication）：把相同数据进行备份，拷贝在不同的机器上。有两类副本
  - 领导者副本（Leader Replica）: 对外提供服务
  - 追随者副本（Follower Replica）：复制 leader 的数据
- 副本工作机制：
  - 生产者向领导者副本写消息
  - 消费者从领导者副本读消息
  - 追随者副本向领导者发送请求，同步最新的消息
- 伸缩性 Scalability：领导者副本累积太多消息之后，单台 Broker 会无法容纳，解决方法就是把数据分割成多份保存在不同的 Broker 上
- 分区（Partitioning）: 为了解决上一条的问题，把该解决方法称为分区
  - 将每个主题划分成多个分区，每个分区是一组有序的消息日志。生产者生产的每一条消息只会被发送到一个分区中；假设向一个有双分区的主题发送消息，消息要么在 0 中要么在 1 中。
  - 副本与分区的联系：
    - 副本是在「分区」这个层级上面定义的。每个分区可以配置若干个副本，其中有 1 个领导者副本和 N-1 个追随者副本。
    - 生产者向分区写入消息，每条消息在分区中的位置用位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、… 、9。

至此可以串起来 kafka 的三层消息结构：

- 第一层是**主体层**：每个主题可以配置 M 个分区，每个分区可以配置 N 个副本
- 第二层是**分区层**：每个分区层的 N 个副本中只能有一个充当领导者，其他的 N-1 个都是追随者，作用是提供数据冗余
- 第三层是**消息层**：分区中包含若干条消息，每条消息从位移 0 开始，依次递增
- 客户端程序只能与分区的领导者进行交互

kafka 持久化消息的方法：

> 总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

- 消费者组：多个消费者实例组成一个组了来消费一组主题。每组主题中的每个分区都只会被组内的一个消费者实例来消费，其他消费者实例不能消费他，引入消费者组的原因是为了提升消费者端的吞吐量。
- 重平衡：当消费者组中的一个实例挂掉后，kafka 可以自动检测到，然后把这个实例负责的分区转移给其他活着的消费者，这个过程被称之为「重平衡」
- 消费者位移：用来记录当前消费到了分区的哪一个位置上。此处的位移和上面的不一样：
  - 上面的**位移**：表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。
  - 此处的**消费者位移**：它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。

小结：

- 消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
- 主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
- 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
- 生产者：Producer。向主题发布新消息的应用程序。
- 消费者：Consumer。从主题订阅新消息的应用程序。
- 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

下图是上面提到的概念：

![20191011211354.png](https://i.loli.net/2019/10/11/ZWFQhSNLlVO8Dt3.png)

为什么 kafka 不支持从追随者读数据，而要从领导者读数据？

谢邀。首先明确一下：主从分离与否没有绝对的优劣，它仅仅是一种架构设计，各自有适用的场景。第二、如你所说，Redis 和 MySQL 都支持主从读写分离，我个人觉得这和它们的使用场景有关。对于那种读操作很多而写操作相对不频繁的负载类型而言，采用读写分离是非常不错的方案——我们可以添加很多 follower 横向扩展，提升读操作性能。反观 Kafka，它的主要场景还是在消息引擎而不是以数据存储的方式对外提供读服务，通常涉及频繁地生产消息和消费消息，这不属于典型的读多写少场景，因此读写分离方案在这个场景下并不太适合。第三、Kafka 副本机制使用的是异步消息拉取，因此存在 leader 和 follower 之间的不一致性。如果要采用读写分离，必然要处理副本 lag 引入的一致性问题，比如如何实现 read-your-writes、如何保证单调读（monotonic reads）以及处理消息因果顺序颠倒的问题。相反地，如果不采用读写分离，所有客户端读写请求都只在 Leader 上处理也就没有这些问题了——当然最后全局消息顺序颠倒的问题在 Kafka 中依然存在，常见的解决办法是使用单分区，其他的方案还有 version vector，但是目前 Kafka 没有提供。最后、社区正在考虑引入适度的读写分离方案，比如允许某些指定的 follower 副本（主要是为了考虑地理相近性）可以对外提供读服务。当然目前这个方案还在讨论中。

作者：huxihx
链接：https://www.zhihu.com/question/327925275/answer/705690755
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

## 03 Kafka 只是消息引擎系统吗？

Apache Kafka 是消息引擎系统，也是一个分布式流处理平台 (Distributed Streaming Platform)

Kafka 自诞生伊始是以消息引擎系统的面目出现在大众视野中的。如果翻看 0.10.0.0 之前的官网说明，你会发现 Kafka 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。

Kafka 在设计之初就旨在提供三个方面的特性：

- 提供一套 API 实现生产者和消费者；
- 降低网络传输和磁盘存储开销；
- 实现高伸缩性架构。

## 04 我应该选择哪种 Kafka？

你知道几种 Kafka？

咦？ Kafka 不是一个开源框架吗，什么叫有几种 Kafka 啊？ 实际上，Kafka 的确有好几种，这里我不是指它的版本，而是指存在多个组织或公司发布不同的 Kafka。你一定听说过 Linux 发行版吧，比如我们熟知的 CentOS、RedHat、Ubuntu 等，它们都是 Linux 系统，但为什么有不同的名字呢？其实就是因为它们是不同公司发布的 Linux 系统，即不同的发行版。虽说在 Kafka 领域没有发行版的概念，但你姑且可以这样近似地认为市面上的确存在着多个 Kafka“发行版”。

1. Apache Kafka：社区版 kafka
2. Confluent Kafka：Confluent Kafka 提供了一些 Apache Kafka 没有的高级特性，比如跨数据中心备份、Schema 注册中心以及集群监控工具等。
3. Cloudera/Hortonworks Kafka

## 05 聊聊 Kafka 的版本号

Scala 编写了 Kafka

Kafka 版本命名：

![20191012213928.png](https://i.loli.net/2019/10/12/A3DxsCKH8Se9N5h.png)

对于 kafka-2.11-2.1.1 的提法，真正的 Kafka 版本号实际上是 2.1.1。那么这个 2.1.1 又表示什么呢？前面的 2 表示大版本号，即 Major Version；中间的 1 表示小版本号或次版本号，即 Minor Version；最后的 1 表示修订版本号，也就是 Patch 号。

## 06 Kafka 线上集群部署方案怎么做

主流的 I/O 模型有 5 种：

1. 阻塞式 I/O
2. 非阻塞式 I/O
3. I/O 多路复用
4. 信号驱动 I/O 
5. 异步 I/O

每种 I/O 模型都有各自典型的使用场景，比如 Java 中 Socket 对象的阻塞模式和非阻塞模式就对应于前两种模型；而 Linux 中的系统调用 select 函数就属于 I/O 多路复用模型；大名鼎鼎的 epoll 系统调用则介于第三种和第四种模型之间；至于第五种模型，其实很少有 Linux 系统支持，反而是 Windows 系统提供了一个叫 IOCP 线程模型属于这一种。

I/O 模型与 Kafka 的关系又是什么呢？实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是 select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能。

